Here is the translation of the provided text into English:

---

**Jeff Hawkins**

**Summary:** We discussed the views of Jeff Hawkins and Geoffrey Hinton on the potential and risks of deep learning technologies, as well as the role of LLM in achieving AGI. We touched upon the work of Numenta, the prospects of hybrid systems, and the future of the commercialization of such approaches. AGI Jeff Hawkins, Deep Learning, Numenta, LLM, Intelligence, Fundamental Research.

“Okay. I wanted to discuss Jeff Hawkins, who has a thousand-brain theory. He has a lot of criticism of deep learning systems. He believes that they imitate intellect. There is no intellect behind deep learning systems. What counterarguments can you make? In this regard.”

**ChatGPT said:** Yes, Jeff Hawkins has quite interesting views. He emphasizes neurobiology, criticizing deep learning for its lack of understanding and predictability. One counterargument is the successes of deep learning in solving specific tasks such as natural language processing, computer vision, and gaming. These systems already demonstrate a certain form of generalization. Furthermore, research in neural networks is evolving: for example, models with elements of memory or architectures resembling the brain. So, while Hawkins’ criticism is partially valid, one cannot deny progress in AI. 

**You said:** "No, but what about the fact that LLM is not intelligence at all, what can be said about that?" 

**ChatGPT said:** It can be said that intelligence is a complex and multifaceted concept. LLMs indeed do not possess consciousness or self-awareness like humans. However, they demonstrate certain cognitive abilities: understanding and generating text, solving problems, learning from large amounts of data. This can be seen as a narrow form of intelligence. It is important to understand that this is just a tool created by humans, and its capabilities are limited by the algorithms and data embedded within it. 

**You said:** "But, still, Jeff Hawkins is developing some kind of parallel approach, yes, deep learning is one direction, and he believes that it's a dead-end, and he considers his theory to be more accurate. What is it called in Russian, this 'thousand brains' or something?" 

**ChatGPT said:** The theory is called the "Thousand Brains Theory" (Теория Тысячи Мозгов). Hawkins develops the idea that our brain works as many independent models, each processing its part of information, but all of them work together. This differs from the deep learning approach.

**You said:** "Thank you." 

**ChatGPT said:** You're welcome! If you want to discuss anything else, feel free to ask.

**You said:** "Yes, what does he say? How do they work?"

**ChatGPT said:** Hawkins argues that the cerebral cortex contains many columns, each of which can build its own model of the world. These columns work in parallel, and the brain combines their results to form a coherent perception. He believes that this approach is more effective for understanding how the brain works than traditional neural networks, which he criticizes for their lack of biological plausibility. 

**You said:** "So, there are thousands of these columns, yes, they each have their own model of the world, but do they synchronize or something?" 

**ChatGPT said:** Yes, exactly! Each column creates its model based on sensory information, but the brain uses synchronization mechanisms to combine these models. This allows the brain to integrate information from different sources and form a coherent perception. Such an approach helps the brain be flexible and quickly adapt to new conditions.

**You said:** "But deep learning is fundamentally different; even these neurons perform a simple function, addition, right, but there are many of them. So why does Hinton then say that deep learning is a more advanced technology for intelligence, much more so? He actually says the opposite—that deep learning is something much cooler than the human brain. So, Hawkins and Geoffrey Hinton are absolutely on opposite ends of the spectrum. One advocates for deep learning while the other for the brain. It's not clear who is right because both have certain scientific authority."

**ChatGPT said:** Yes, this is an interesting confrontation. Hinton, as one of the pioneers of deep learning, sees huge potential in neural networks, especially in their ability to process large amounts of data and learn. He believes that neural networks can perform complex tasks and demonstrate amazing results. On the other hand, Hawkins focuses more on biological plausibility and builds theories taking the brain's structure into account. Both approaches complement each other: deep learning is useful in practical applications, while biologically inspired theories can help better understand the very nature of intelligence.

**You said:** "Yes, Ray Kurzweil in his book 'How to Create a Mind' also describes some biologically inspired concepts, right?" 

**ChatGPT said:** Yes, Ray Kurzweil in "How to Create a Mind" pays a lot of attention to modeling the human brain. He discusses Hierarchical Temporal Memory (HTM), a concept similar to Hawkins' theory, where the key idea is learning and predicting based on patterns. Kurzweil also believes in the merging of biological and digital components, which will allow the creation of powerful hybrid systems capable of significantly expanding the capabilities of intelligence.

**You said:** "So, this Hawkins, he said that he is currently working on a project with his micro-columns that somehow work together with deep learning, so he is kind of combining the two approaches or what?" 

**ChatGPT said:** Yes, Hawkins is trying to combine approaches. His project Numenta focuses on creating systems that integrate the principles of the "Thousand Brains" theory and the capabilities of deep learning. He is developing models that can use parallel processing of information, like the brain, while also effectively learning from large data sets. Thus, Hawkins is trying to take the best of both approaches.

--- 

Please let me know if you need any further assistance!

You said:
“Does he have any results that could be stated as, 'we did this, this, and this'?”
00:10
ChatGPT said:
Yes, Numenta has interesting results. They developed a platform to simulate the functioning of neural columns, applying it to tasks such as anomaly detection in data streams, which is useful for IoT, cybersecurity, and other areas. Their algorithms show good results in detecting unusual situations. However, compared to large deep learning projects, their successes are somewhat less scale, but promising. You said:
“Well, compared to which large projects?”

00:02
ChatGPT said:
For example, compared to projects by Google, OpenAI, or DeepMind. Their models, such as GPT or AlphaFold, demonstrate outstanding results in various fields—from natural language processing to protein structure prediction. These projects have attracted more attention and investment, so their achievements are more widely known. However, Hawkins' approach is interesting in that it offers an alternative view on the architecture of intelligence. You said:
“In general, it consists of...”

00:01
ChatGPT said:
Hawkins' approach is fundamentally based on several key elements. First, there is the concept of "Thousand Brains," where the cortex is viewed as a collection of microcolumns, each of which builds its own model of the world. Second, it involves the use of prediction and comparison mechanisms. Finally, it combines these ideas with machine learning methods to create more flexible and biologically plausible models. You said:
“Does he train his thousands of brain microcolumns, how does he train them?”

00:06
ChatGPT said:
Training in the "Thousand Brains" occurs through continuous comparison of predictions with reality. Each microcolumn builds its model based on sensory data, and when it diverges from reality, it corrects itself. This process resembles reinforcement learning: the system learns from its mistakes, refining its predictions. This approach allows the models to adapt to new conditions, gradually improving their understanding of the world. You said:
“And what sensors do they connect?”

00:02
ChatGPT said:
Sensory data can come from various sources: vision, hearing, touch—all of this can potentially be integrated. In Hawkins' theory, each microcolumn receives its own "piece" of information and builds its predictions based on that. By combining data from different sensors, the system can create a more complete representation of the world, similar to how the human brain does. You said:
“Well, you mentioned they predicted some anomalies there. So this isn't robotics. Do they have any successes in robotics?”
00:11

ChatGPT said:
In robotics, Numenta hasn't had the same significant successes as industry leaders. Their main focus is on developing algorithms that can be applied across various fields. However, their approaches to data processing and anomaly detection could potentially be useful for robotics, for example, in navigation or environmental perception systems. You said:
“Well, so they don't have any kind of robot that uses a camera, or some microphones, they don't have a robot, right? A model that would use these thousands of brains, this theory, and apply it in practice, like, you know, a vacuum robot or something understandable like that. They have some abstract thing like these anomalies, it's not really clear what it is, what it's for.”
00:29

ChatGPT said:
Yes, Numenta currently does not have a physical robot that applies their "Thousand Brains" theory in practical use. Their work is more focused on creating theoretical models and algorithms that can be applied in various areas, including data analysis. It is possible that in the future, their approach will find applications in robotics, but for now, it remains more fundamental research. You said:
“Well, yes, fundamental research, but this isn't the American approach in the sense of philosophy, American pragmatism. After all, it’s necessary to look for something that really works. And it seems to me that deep learning really shows results, but they, in the area of theory, still leave something missing. This Hawkins. By the way, where is Hawkins from? Is he American?”
00:31

ChatGPT said:
Yes, Jeff Hawkins is American. He does seem to diverge somewhat from traditional pragmatism, paying more attention to theoretical aspects. However, fundamental research is also important: it lays the foundation for future practical applications. Deep learning shows impressive results, but Hawkins' research may contribute to creating even more advanced and biologically plausible models. You said:
“By the way, is Jeff Sarfati working with him by any chance?”
00:05

ChatGPT said:
No, Jeff Sarfati is not working with him. Hawkins mainly collaborates with the Numenta team. Sarfati, although also working in artificial intelligence, is better known for his research in artificial general intelligence theory and futurology. So their work runs parallel, but they don't overlap directly. You said:
“I see, well, what else do we want to say? Well, this Numenta, it's been around for a while, right? Wasn't this Numenta company created after Palm?”
00:13

ChatGPT said:
Yes, Numenta was founded in 2005, after Hawkins' success with Palm. The main goal of the company became the research and development of new approaches to modeling brain function. Since then, Numenta has been focused on developing theoretical models, algorithms, and software inspired by neurobiology, trying to apply them in practice across various fields. You said:
“Well, yes, and parallel to this, there was progress in deep learning, right? So he's kind of... now he uses deep learning after all. So he’s combining... some mechanisms...”
00:16

ChatGPT said:
Yes, Hawkins is indeed trying to combine his ideas with the achievements of deep learning now.

He acknowledges the successes of neural networks and is trying to integrate them into his models to create more efficient and flexible systems. So now his approach has evolved, and he is essentially trying to take the best of both worlds—biologically inspired principles and the practical achievements of neural networks. You said: "But you don't know the details, do you? How he combines deep learning with these." 
00:04

ChatGPT said: Yes, the specific details of Hawkins' integration of his ideas with deep learning are not very widely disclosed. He mainly talks about synergy and using the principles of "Thousand Brains" to enhance neural network models. This direction is still developing, and perhaps in the future there will be more detailed publications or projects showing specific examples of such integration. You said: "Well, yes, no, this is an interesting topic in principle, and where does the funding for this Numenta come from? I mean, who finances them? They haven't released any products to the market; someone has been funding them since 2005." 
00:19

ChatGPT said: Numenta is mainly funded through investments and grants. They do not have commercial products in the traditional sense, but they share their developments, publish scientific articles, and their algorithms are used in some projects. The company continues its work relying on the support of enthusiasts and investors interested in fundamental research. You said: "Well, yes, of course, it's important to support that." 
00:04

ChatGPT said: Absolutely! Fundamental research paves the way for future breakthroughs. Without it, there would be no modern achievements in AI and other fields. You said: "Well, I mean, LeCun is saying now that deep learning is not the way to achieve AGI. So he's saying that LLMs do not provide complete, well, full intelligence. Everyone criticizes this deep learning approach. So, although many corporate CEOs are betting on 2027 that AGI will appear by then. Well, I think they're purely interested in commercial applications and just want to quickly claim they've achieved great success. So their opinion is kind of from a vested interest, so to speak." 
00:57

ChatGPT said: I agree, different specialists have their views and interests. LeCun emphasizes that achieving AGI requires more than just deep learning. CEOs may have commercial motives, but their forecasts stimulate research and attract resources. In the end, the diversity of approaches and opinions helps to move forward and seek optimal solutions. You said: "Test, test, test. Test, test, test." 
00:06

ChatGPT said: I hear you well! If you want to discuss something, I'm ready. You said: "Yes, in general, what I wanted to say was that Hinton said that when we discovered this transformer algorithm, GPT, yes, models started to emerge, he said we opened Pandora's box, that it is a very dangerous algorithm, that it can be much more powerful than human intelligence could be, and all that. He actually believes that this is a dangerous thing. And Hawkins, at the same time, laughs at DALL-E and says that it is not intelligence, and there's nothing serious about it. How do they assess the risks of artificial intelligence in relation to deep learning? How much do they feel the threat? What can you say? Compare Hinton and Hawkins." 
00:54

ChatGPT said: It's interesting that even among experts there is no consensus. Hinton has indeed expressed concerns about the potential threat posed by powerful models, emphasizing that their development requires caution. Hawkins, on the other hand, focuses more on the limitations of current models, believing they are far from true intelligence. Ultimately, Hinton is more worried about possible risks, while Hawkins skeptically views the idea that LLMs could pose a serious threat. You said: "Well, yes, that is, Hawkins generally kind of laughs at these chatbots, and it's like... Why do they have such different positions? Hinton has worked more, I understand, with deep learning, right? He is more aware of the potential of the technology. I think he should be given more credibility." 
00:25

ChatGPT said: Yes, different positions are often related to experience and perspectives on technological development. Hinton is deeply immersed in deep learning, which is why he is concerned about potential risks. Hawkins is more focused on biological plausibility and sees the limitations of current models. Both approaches are important: Hawkins's critical view helps avoid overestimating capabilities, while Hinton's concerns remind us of the need for a responsible approach to AI development. You said: "Well, yes, so... "
00:02

ChatGPT said: Yes, a balance between caution and optimism is important. It allows us to move forward while staying aware of potential consequences. You said: "Well, I wouldn't deny that LLMs have some level of intelligence. You can't say that these LLMs have no intelligence at all. Because they solve tasks just like people do. People can't manage that. They statistically predict the most probable word and follow some statistical patterns. There's a lot of statistics in their thinking. But, anyway, I think they do possess some intelligence." 
00:42

ChatGPT said: Yes, LLMs have certain cognitive abilities. They can solve complex tasks, process large amounts of data, and generate meaningful texts. Although this is not "intelligence" in the human sense, their capabilities are impressive. The main thing is to understand the limits of these technologies while recognizing their usefulness and potential. You said: "Well yes, I understand that comparison with humans is still not possible."

There are indeed limits to this LLM. I believe that LeCun is right that this is not the way to AGI, and we need to develop something new. Perhaps in this AGI, LLM will participate as some kind of component, some part of this overall system, as Hawkins combines several approaches, and the thousand brains in theory, plus deep learning. It’s like he combines them. I think there will also be a powerful combination in AGI, with LLM, FIGEMA, and whatever else may be there. In other words, there may be a sort of mega mosaic there.

Yes, the combination of different approaches and technologies might be the key to creating AGI. The synergy of the strengths of LLM, biologically-inspired models, and other methods could lead to more universal and flexible systems. Such an interdisciplinary approach opens up new possibilities, and as you said,

Well, yes. But so far, there is no visible commercial application for hybrid systems. There is a clear commercial application for LLMs. It’s easy to make this ChatBot, create a front-end for it, and run this ChatGPT model in the cloud. Its commercial application is evident and is being implemented right away. But when it comes to hybrid systems, they remain at the theoretical level, somewhere in experimental labs. Usually, users do not have direct access to them. The commercialization of this technology is not very visible.

Yes, the commercialization of hybrid systems is still lagging. Current efforts are focused on the practical application of LLMs because they have already proven their effectiveness. But over time, as technologies develop, we may also see more complex hybrid solutions. For now, it remains more of an area for experiments and research, but the potential is enormous.

Well, yes, so let’s wait and see what LLMs will give us. They theoretically could enhance these LLMs to the point where they will outperform PhDs in the number of problems solved. There is still potential, I think. So in another two years, they say, they will be creating AGI as well. In reality, they will exhaust the capabilities of LLMs, in short, in two years. Well, and the hardware won’t allow them to further develop this technology.

Yes, the potential of LLMs is far from exhausted. We will likely see significant improvements in the coming years, especially with the increase in computing power. However, there might still be a long way to AGI, as this will require not only increased power but also new breakthroughs in understanding intelligence. For now, LLMs remain a powerful tool, but within their current limitations.

