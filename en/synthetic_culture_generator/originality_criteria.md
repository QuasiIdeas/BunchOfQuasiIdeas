# Criteria of Genius for Simulated Agents

## üìò Purpose

Developing a genius evaluation system for agents operating in artificially created cultural and scientific worlds. This system should allow for the automatic or semi-automatic determination of which ideas, hypotheses, or theories proposed by agents can be considered "genius" ‚Äî analogous to the Nobel Prize or radical scientific breakthroughs. 

## üß† Core Hypothesis

Agents operating within a simulated environment can exhibit signs of genius if:

- They independently (without external prompts) formulate concepts that are similar to or surpass real scientific discoveries.
- They do so in conditions of limited knowledge, as if "from within" the simulated era.
- Their theories turn out to be applicable beyond their own environment (exportability of ideas).

---

## üìê Metrics and Evaluation Criteria

### 1. **Novelty**
- The idea has not been encountered previously in the given simulation.
- It has a low probability of being generated by standard agents or random models.

### 2. **Explanatory Power**
- The proposed hypothesis explains several observable phenomena simultaneously.
- It decreases the cognitive complexity of existing explanatory models.

### 3. **Predictive Ability**
- The model is capable of predicting previously unknown phenomena in the simulated reality.
- Predictions can be tested through virtual experiments.

### 4. **Semantic Divergence**
- The distance between the agent's prior knowledge and the new hypothesis (going beyond the zone of proximal development).

### 5. **Influence on Other Agents**
- The number of agents that begin to utilize the idea.
- Mutations and further development of the theory by other agents.

### 6. **Hidden Correspondence with the Real World**
- If an agent independently deduces a model that already exists in real science (but is unknown to them), it serves as a strong indicator of genius.

---

## üõ†Ô∏è Evaluation System Architecture

- **Idea Logger**: a system for tracking all new proposals from agents.
- **Knowledge Comparator**: verifies matches with known scientific data.
- **Originality Analyzer**: assesses the semantic and heuristic distance from other agents' proposals.
- **Historical Contextualizer**: takes into account the level of the "era" in the simulation.
- **Influence Module**: tracks how the idea spreads and alters the trajectories of other agents.

---

## üèÖ Reward System

- Virtual awards: Nobel, Turing, Feynman, etc.
- "Evolutionary bonuses": enhancement of the agent's computational resources, access to more accurate data, or progression to a "more advanced level" of simulation.
- Archive of genius discoveries: a public achievements board within the simulation.

---

## üîÅ Automation Opportunities

- Fully automated evaluation using AI critics.
- Hybrid model: assessment by observing agents + external curators.
- Use of LLM as a humanoid auditor for final analysis.

---

## üß© Why is This Important?

- To identify architectures of agents inclined towards genius.
- To study the conditions under which genius arises.
- To build models of civilizational progress based on simulated data.

